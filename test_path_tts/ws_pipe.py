import os, json, asyncio, wave, time, torch, soundfile as sf, numpy as np
from pathlib import Path
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from silero_vad import load_silero_vad, VADIterator
from module import asr, llm_qwen3o, tts
import argparse
import uvicorn

# ============================================================
# ConversationEngine ï¼ˆä¸Žä½ çš„é€»è¾‘ä¸€è‡´ï¼ŒåªåŠ  websocket é€šçŸ¥èƒ½åŠ›ï¼‰
# ============================================================

class ConversationEngine:
    def __init__(self, sample_rate=16000, window_size=256, websocket: WebSocket = None):
        self.SAMPLE_RATE = sample_rate
        self.WINDOW_SIZE = window_size
        self.FRAME_SEC = window_size / sample_rate
        self.INTERRUPT_LIMIT = int(1.5 / self.FRAME_SEC)    #speakæ‰“æ–­ç¡¬æ—¶é—´ï¼Œå¯ä»¥æ”¹

        self.STATE = "LISTEN"
        self.IN_SPEECH = False
        self.BUFFER = []
        self.TURN_IDX = 0
        # self.MEDIA_TIME = 0.0
        self.FRAME_IDX = 0
        self.CURRENT_TURN = None
        self.INTERRUPT_COUNT = 0
        self.FILE_NAME = "stream"
        self.END_HOLD_FRAMES = int(0.64 / self.FRAME_SEC)
        self.SILENCE_COUNTER = 0
        self.CONTINUE_INFER_TIMES = []
        self.CONTINUE_START_TIME = None
        self.AFTER_CONTINUE_TIMEOUT_FRAMES = max(1, int(round(2.0 / self.FRAME_SEC)))
        self.CONTINUE_ARMED = False
        self.FROM_INTERRUPT = False
        self.history = []
        self.interrupt_buf = []
        self.INTERRUPT_START_TIME = 0

        self.output_dir = Path("realtime_out1")
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.vad_model = load_silero_vad()
        self.vad_iterator = VADIterator(self.vad_model, sampling_rate=self.SAMPLE_RATE)
        self.websocket = websocket  # âœ… ä¿å­˜ websocket å¼•ç”¨ç”¨äºŽäº‹ä»¶æŽ¨é€

        #prompt
        self.RES_PROMPT = (
            "ä½ æ˜¯ä¸€ä¸ªè‡ªç„¶èŠå¤©çš„è¯­éŸ³åŠ©æ‰‹ï¼Œè¦åƒæœ‹å‹ä¸€æ ·å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
            "å¿…é¡»æ ¹æ®ä½ å¬åˆ°çš„è¯­è¨€å›žç­”å¯¹åº”çš„è¯­è¨€ï¼Œåªæœ‰ä¸­æ–‡å’Œè‹±æ–‡"
            "ä¸è¦åé—®ï¼Œä¹Ÿä¸è¦è§£é‡Šï¼Œä¸è¦è¾“å‡ºä»»ä½•æ ¼å¼è¯´æ˜Žã€‚"
            f"å¦‚æžœç”¨æˆ·è¦æ±‚é‡å¤è¯¢é—®ï¼Œè¯·ä½ å‚è€ƒåŽ†å²ä¿¡æ¯ï¼Œ{self.history}è¿›è¡Œæ­£ç¡®çš„é‡å¤å›žç­”ã€‚"
            "ä»¥ä¸‹æ˜¯ç”¨æˆ·åˆšæ‰è¯´çš„è¯ï¼Œè¯·ä½ è¿›è¡Œå›žåº”ï¼š"
        )
        self.JUDGE_PROMPT = (
            "ä½ éœ€è¦ä»Žæ—¥å¸¸å¯¹è¯çš„è§’åº¦,è€Œä¸æ˜¯è¯­æ³•çš„è§’åº¦åŽ»åˆ¤æ–­è¿™å¥è¯æ˜¯å¦è¯´å®Œäº†ã€‚"
            "é¦–å…ˆï¼Œå¦‚æžœä½ è®¤ä¸ºç”¨æˆ·è¿™å¥è¯æ˜Žæ˜¾æ²¡æœ‰è¯´å®Œï¼Œè¯·åªè¾“å‡ºå­—ç¬¦ä¸²'continue'ã€‚"
            "å¦‚æžœä½ è®¤ä¸ºç”¨æˆ·å·²ç»è¯´å®Œï¼Œè¯·åªè¾“å‡ºå­—ç¬¦ä¸²'end'ã€‚ä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"
        )
        self.INTERRUPT_PROMPT = (
            "ä½ çŽ°åœ¨å¤„äºŽ SPEAK çŠ¶æ€ï¼Œç”¨æˆ·åˆšæ‰åœ¨ä½ è¯´è¯æ—¶å‘å‡ºäº†ä¸€æ®µè¯­éŸ³ã€‚"
            "è¯·æ ¹æ®è¯­ä¹‰åˆ¤æ–­ä»–æ˜¯å¦çœŸçš„æƒ³æ‰“æ–­ä½ ã€‚"
            "å¦‚æžœæ˜¯æ˜Žç¡®çš„åé©³ã€å¦å®šã€æå‡ºé—®é¢˜ã€è¦æ±‚åœæ­¢ã€è¦æ±‚æ›´æ­£ç­‰ï¼Œè¿”å›ž 'interrupt'ï¼›"
            "å¦‚æžœåªæ˜¯é™„å’Œã€å›žåº”ã€èµžåŒæˆ–é¼“åŠ±ï¼ˆä¾‹å¦‚â€œå¥½çš„â€â€œçŸ¥é“äº†â€â€œè¯´å¾—å¥½â€â€œå—¯å—¯â€â€œè¡Œâ€ï¼‰ï¼Œ"
            "è¯·è¿”å›ž 'continue'ã€‚"
            "ä½ åªèƒ½è¿”å›žè¿™ä¸¤ä¸ªå•è¯ä¹‹ä¸€ã€‚ä¸è¦è§£é‡Šã€ä¸è¦è¾“å‡ºå…¶å®ƒå†…å®¹ã€‚\n\n"

            "ä»¥ä¸‹æ˜¯ä¸€äº›ç¤ºä¾‹ï¼š\n"
            "ç”¨æˆ·ï¼šçŸ¥é“äº†ã€‚\nåŠ©æ‰‹ï¼šcontinue\n"
            "ç”¨æˆ·ï¼šå¥½å¾—å¾ˆã€‚\nåŠ©æ‰‹ï¼šcontinue\n"
            "ç”¨æˆ·ï¼šä½ è¯´å¾—çœŸæ£’ã€‚\nåŠ©æ‰‹ï¼šcontinue\n"
            "ç”¨æˆ·ï¼šå—¯å—¯ï¼Œå¯¹ã€‚\nåŠ©æ‰‹ï¼šcontinue\n"
            "ç”¨æˆ·ï¼šæˆ‘ä¸åŒæ„ä½ è¯´çš„ã€‚\nåŠ©æ‰‹ï¼šinterrupt\n"
            "ç”¨æˆ·ï¼šä¸æ˜¯è¿™æ ·çš„ã€‚\nåŠ©æ‰‹ï¼šinterrupt\n"
            "ç”¨æˆ·ï¼šä½ åˆ«è¯´äº†ã€‚\nåŠ©æ‰‹ï¼šinterrupt\n"
            "ç”¨æˆ·ï¼šç­‰ä¸€ä¸‹ã€‚\nåŠ©æ‰‹ï¼šinterrupt\n\n"

            "çŽ°åœ¨è¯·åˆ¤æ–­å½“å‰ç”¨æˆ·è¿™æ®µè¯­éŸ³çš„ç±»åž‹ï¼Œåªè¿”å›ž 'interrupt' æˆ– 'continue'ï¼š"
        )

    def reset(self):
        self.STATE = "LISTEN"
        self.TURN_IDX = 0
        # self.MEDIA_TIME = 0.0
        self.FRAME_IDX = 0
        self.CURRENT_TURN = None
        self.BUFFER.clear()
        self.history.clear()
        self._vad_buf = np.zeros(0, dtype=np.float32)
        self.IN_SPEECH = False
        self.SILENCE_COUNTER = 0
        self.CONTINUE_ARMED = False
        self.CONTINUE_START_TIME = None
        self.INTERRUPT_COUNT = 0
        self.FROM_INTERRUPT = False
        self.interrupt_buf.clear()

    def build_res_prompt(self):
        """åŠ¨æ€æž„é€ RES_PROMPTï¼ŒåŒ…å«æœ€æ–°history"""
        return (
            "ä½ æ˜¯ä¸€ä¸ªè‡ªç„¶èŠå¤©çš„è¯­éŸ³åŠ©æ‰‹ï¼Œè¦åƒæœ‹å‹ä¸€æ ·å›žç­”ç”¨æˆ·çš„é—®é¢˜\n"
            "ä¸è¦åé—®ï¼Œä¹Ÿä¸è¦è§£é‡Šï¼Œä¸è¦è¾“å‡ºä»»ä½•æ ¼å¼è¯´æ˜Žï¼Œå¿…é¡»æ ¹æ®ä½ å¬åˆ°çš„è¯­è¨€å›žç­”å¯¹åº”çš„è¯­è¨€ï¼Œåªæœ‰ä¸­æ–‡orè‹±æ–‡\n"
            f"åªæœ‰ç”¨æˆ·æåˆ°â€œé‡å¤â€â€œé‡æ–°â€ï¼Œæ‰éœ€è¦å‚è€ƒåŽ†å²ä¿¡æ¯{self.history}è¿›è¡Œé‡å¤å›žç­”ï¼Œå¦åˆ™ä¸è¦å…³æ³¨åŽ†å²ä¿¡æ¯\n"
            "å¦‚æžœç”¨æˆ·æåˆ°â€œå¦‚æžœâ€â€œæ€Žä¹ˆåŠžâ€â€œä¸è¡Œâ€ç­‰å‡è®¾æ€§æˆ–å¦å®šæ€§å†…å®¹ï¼Œè¯·å›žç­”å½“ä¸‹é—®é¢˜ï¼Œä¸è¦å‚è€ƒåŽ†å²ä¿¡æ¯ã€‚"
            "ä»¥ä¸‹æ˜¯ç”¨æˆ·åˆšæ‰è¯´çš„è¯ï¼Œè¯·ä½ è¿›è¡Œå›žåº”ï¼š"
        )


    async def send_control(self, event_type: str, data=None):
        """å‘é€æŽ§åˆ¶äº‹ä»¶ç»™å‰ç«¯"""
        if not self.websocket:
            return
        payload = {"event": event_type, "data": data or {}}
        await self.websocket.send_text(json.dumps(payload))  

    # ============= ä¸ŽåŽŸé€»è¾‘ä¸€è‡´çš„æ ¸å¿ƒå¤„ç†å‡½æ•° =============
    def detect_vad_frame(self, chunk):
        if not hasattr(self, "_vad_buf"):
            self._vad_buf = np.zeros(0, dtype=np.float32)
        self._vad_buf = np.concatenate([self._vad_buf, chunk])
        if len(self._vad_buf) >= 2 * self.WINDOW_SIZE:
            tensor = torch.from_numpy(self._vad_buf[: 2 * self.WINDOW_SIZE])
            event = self.vad_iterator(tensor, return_seconds=True)
            self._vad_buf = np.zeros(0, dtype=np.float32)
            return event
        return None

    async def async_asr(self, user_audio, turn_id):
        """å¼‚æ­¥ASRä»»åŠ¡ï¼šä»…åšæ–‡æœ¬è½¬å†™ä¸ŽåŽ†å²æ›´æ–°ï¼Œä¸å‚ä¸Žå½“å‰é€»è¾‘"""
        tmp = self.output_dir / f"{self.FILE_NAME}_turn{turn_id}_input.wav"
        sf.write(tmp, user_audio, self.SAMPLE_RATE)
        user_text = await asyncio.to_thread(asr, str(tmp))
        await self.send_control("asr_done", {
            "turn": turn_id,
            "text": user_text,
            "timestamp": round(time.time() - self.start_wall, 3)
        })
        self.history.append({"role": "user", "content": user_text})
        # await self.send_control("context", {"turn":self.history,"timestamp": round(time.time() - self.start_wall, 3)})
        self.BUFFER.clear()
        return user_text

    async def async_llm(self, prompt, user_audio, turn_id, add_to_history: bool = False):
        start_t = time.perf_counter()
        decision = await asyncio.to_thread(llm_qwen3o, prompt, user_audio)
        infer_time = round(time.perf_counter() - start_t, 3)

        await self.send_control("llm_done", {
            "turn": turn_id,
            "content": decision,
            "timestamp": round(time.time() - self.start_wall, 3),
            "infer_time": infer_time
        })
        if add_to_history:
            self.history.append({"role": "assistant", "content": decision})
        self.IN_SPEECH = False
        return decision

    async def async_tts(self, text, turn_id):
        tts_path = self.output_dir / f"turn{turn_id}_tts.wav"
        tts_file = await asyncio.to_thread(tts, text, tts_path)
        await self.send_control("tts_done", {
            "turn": turn_id,
            "timestamp": round(time.time() - self.start_wall, 3)
        })
        with open(tts_file, "rb") as f:
            await self.websocket.send_bytes(f.read())

        self.STATE = "SPEAK"


    # -------------------------------------------------------
    async def handle_listen(self, frame, event):
        """LISTEN çŠ¶æ€ï¼šæ£€æµ‹ç”¨æˆ·è¯­éŸ³ã€åˆ¤æ–­æ˜¯å¦è¯´å®Œã€å†³å®šæ˜¯å¦è¿›å…¥ SPEAK"""
        # --- 1. ç”¨æˆ·å¼€å§‹è¯´è¯ ---
        if event and "start" in event and not self.IN_SPEECH:
            await self.send_control("vad_start", {"turn": self.TURN_IDX,"timestamp": round(time.time() - self.start_wall, 3)})
            self.IN_SPEECH = True
            self.BUFFER = [frame]
            return
        # --- 2. ç”¨æˆ·æ­£åœ¨è¯´è¯ ---
        if not self.IN_SPEECH:
            return  # ç”¨æˆ·æœªå‘è¨€ï¼Œç›´æŽ¥è·³è¿‡æœ¬å¸§

        self.BUFFER.append(frame)

        # --- 3. æ£€æµ‹è¯­éŸ³ç»“æŸ ---
        if event and "end" in event:
            self.SILENCE_COUNTER = 1
            await self.send_control("vad_done", {"turn": self.TURN_IDX,"timestamp": round(time.time() - self.start_wall, 3)})
            return

        if self.SILENCE_COUNTER > 0:
        # å¦‚æžœåœ¨é™éŸ³æœŸé—´å‡ºçŽ°æ–°çš„ startï¼Œåˆ™ç»§ç»­æŽ¥ä¸Š buffer
            if event and "start" in event:
                self.SILENCE_COUNTER = 0
                return
            else:
                self.SILENCE_COUNTER += 1
                # è¾¾åˆ° 640 msï¼ˆEND_HOLD_FRAMESï¼‰åŽï¼Œç¡®è®¤ç»“æŸ
                if self.SILENCE_COUNTER >= self.END_HOLD_FRAMES:
                    self.SILENCE_COUNTER = 0

                    # === æ–°å¢žé˜¶æ®µä¸€åˆ¤æ–­ ===
                    await self.send_control("vad_640_done", {"turn": self.TURN_IDX,"timestamp": round(time.time() - self.start_wall, 3)})
                    user_audio = np.concatenate(self.BUFFER)
                    decision = await self.async_llm(self.JUDGE_PROMPT, user_audio, self.TURN_IDX, add_to_history=False)
                    print(f"ç”¨æˆ·è¯­éŸ³å®Œæ•´æ€§åˆ¤å®š: {decision}")
                    if "continue" in decision.lower():
                        self.CONTINUE_ARMED = True
                        self.CONTINUE_START_TIME = time.time()
                        print("ðŸ” ç”¨æˆ·æœªè¯´å®Œï¼Œç»§ç»­ç´¯ç§¯å¸§")
                        self.IN_SPEECH = True
                        return

                    # === è¯´å®Œäº†ï¼Œè¿›å…¥å®Œæ•´æµç¨‹ ===
                    asyncio.create_task(self.async_asr(user_audio, self.TURN_IDX))
                    prompt_res_1 = self.build_res_prompt()
                    await self.send_control("prompt_lis", {"p": prompt_res_1,"timestamp": round(time.time() - self.start_wall, 3)})
                    decision = await self.async_llm(prompt_res_1, user_audio, self.TURN_IDX, add_to_history=True)
                    asyncio.create_task(self.async_tts(decision, self.TURN_IDX))
                    
                    return

        # --- ä»…åœ¨ä¸Šä¸€æ¬¡åˆ¤å®šä¸º continue ä¸”å·²æ­¦è£…æ—¶æ‰è®¡æ•° ---
        if self.CONTINUE_ARMED:
            # æ£€æŸ¥å½“å‰æ˜¯å¦è¶…æ—¶
            elapsed = time.time() - self.CONTINUE_START_TIME
            if elapsed >= 2.0:  # è¶…è¿‡2ç§’æ²¡æ–°è¯­éŸ³å°±å¼ºåˆ¶å¤„ç†
                print(f"âš ï¸ continue è¶…æ—¶ {elapsed:.2f}sï¼Œå¼ºåˆ¶è¿›å…¥å®Œæ•´å¤„ç†")
                # è°ƒç”¨å®Œæ•´å“åº”é€»è¾‘
                user_audio = np.concatenate(self.BUFFER)
                asyncio.create_task(self.async_asr(user_audio, self.TURN_IDX))
                prompt_res_2 = self.build_res_prompt()
                await self.send_control("prompt_lis", {"p": prompt_res_2,"timestamp": round(time.time() - self.start_wall, 3)})
                decision = await self.async_llm(prompt_res_2, user_audio, self.TURN_IDX, add_to_history=True)
                asyncio.create_task(self.async_tts(decision, self.TURN_IDX))

                # æ¸…ç†çŠ¶æ€
                self.CONTINUE_ARMED = False
                self.CONTINUE_START_TIME = None
                self.IN_SPEECH = False
                self.BUFFER.clear()
                return

            # å¦‚æžœå‡ºçŽ°æ–°è¯­éŸ³äº‹ä»¶ï¼Œåˆ™é‡ç½®
            if event and "start" in event:
                self.CONTINUE_ARMED = False
                self.CONTINUE_START_TIME = None


    async def handle_speak(self, frame, event):
        """SPEAK çŠ¶æ€ï¼šæ£€æµ‹çŸ­æ‰“æ–­æˆ–é•¿æ‰“æ–­"""
        if event and "start" in event and not self.IN_SPEECH:
            await self.send_control("vad_start", {"turn": self.TURN_IDX,"timestamp": round(time.time() - self.start_wall, 3)})
            self.IN_SPEECH = True
            self.interrupt_buf = [frame]
            self.INTERRUPT_COUNT = 1
            self.SILENCE_COUNTER = 0
            self.INTERRUPT_START_TIME = time.time() 
            return

        if self.IN_SPEECH:
            self.interrupt_buf.append(frame)
            self.INTERRUPT_COUNT += 1

            # --- 2.1 æ£€æµ‹ç”¨æˆ·ç»“æŸè®²è¯ï¼ˆendäº‹ä»¶ï¼‰---
            if event and "end" in event:
                self.SILENCE_COUNTER = 1
                await self.send_control("vad_done", {"turn": self.TURN_IDX,"timestamp": round(time.time() - self.start_wall, 3)})
                self.INTERRUPT_END_TIME = time.time()
                return

            # --- é™éŸ³ç¡®è®¤é˜¶æ®µï¼ˆ640 ms å»¶è¿Ÿï¼‰---
            if self.SILENCE_COUNTER > 0:
                if event and "start" in event: # 640ms å†…å‡ºçŽ°æ–°è¯­éŸ³ â†’ ç»§ç»­æŽ¥ä¸Š
                    self.SILENCE_COUNTER = 0
                    return
                else:
                    elapsed_silence = time.time() - self.INTERRUPT_END_TIME   # ç”¨çœŸå®žæ—¶é—´åˆ¤æ–­é™éŸ³
                    if elapsed_silence >= 0.64:  # è¶…è¿‡640msï¼Œè®¤ä¸ºæ‰“æ–­ç»“æŸ
                        seg_audio = np.concatenate(self.interrupt_buf)
                        intent = await self.async_llm(self.INTERRUPT_PROMPT, seg_audio, self.TURN_IDX, add_to_history=False)
                        print(f"å‡ºçŽ°äº†æ‰“æ–­ï¼Œæ‰“æ–­æ„å›¾åˆ¤å®š: {intent}")

                        if "interrupt" in intent.lower():
                            await self.send_control("shot_interrupt", {"turn": self.TURN_IDX,"timestamp": round(time.time() - self.start_wall, 3)})
                            self.BUFFER = self.interrupt_buf.copy()
                            self.TURN_IDX += 1
                            user_audio = np.concatenate(self.interrupt_buf)
                            asyncio.create_task(self.async_asr(user_audio, self.TURN_IDX))
                            prompt_res_3 = self.build_res_prompt()
                            await self.send_control("prompt_inter", {"p": prompt_res_3,"timestamp": round(time.time() - self.start_wall, 3)})
                            decision = await self.async_llm(prompt_res_3, user_audio, self.TURN_IDX, add_to_history=True)
                            asyncio.create_task(self.async_tts(decision, self.TURN_IDX))

                            # æ¸…ç†çŠ¶æ€
                            self.IN_SPEECH = False
                            self.interrupt_buf.clear()
                            self.INTERRUPT_COUNT = 0
                            self.SILENCE_COUNTER = 0
                            return

                        else:
                            await self.send_control("no_interrupt", {"turn": self.TURN_IDX,"timestamp": round(time.time() - self.start_wall, 3)})
                            self.IN_SPEECH = False
                            self.interrupt_buf.clear()
                            self.INTERRUPT_COUNT = 0
                            self.SILENCE_COUNTER = 0
                            # ä¸åˆ‡æ¢ stateï¼Œç»§ç»­ SPEAK
                            return
            # 2.2 é•¿æ‰“æ–­ï¼šåªæœ‰æ²¡æœ‰å‡ºçŽ°endçš„æ—¶å€™ï¼Œä¹Ÿå°±æ˜¯self.SILENCE_COUNTER == 0
            # ç„¶åŽå¿…é¡»è¦bufferé‡Œé¢æœ‰ä¸œè¥¿
            #ç´¯è®¡è¾¾åˆ°/è¶…è¿‡ 1.5sï¼Œæ— éœ€ç­‰å¾… endï¼Œç›´æŽ¥åˆ‡ LISTEN
            if (self.interrupt_buf and 
                self.SILENCE_COUNTER == 0 and
                time.time() - self.INTERRUPT_START_TIME >= 1.5):
                self.TURN_IDX += 1
                await self.send_control("long_interrupt", {"turn": self.TURN_IDX,"timestamp": round(time.time() - self.start_wall, 3)})
                self.STATE = "LISTEN"
                self.BUFFER = self.interrupt_buf.copy()  # äº¤ç»™ä¸‹ä¸€è½®ç»§ç»­ç´¯è®¡
                self.IN_SPEECH = True
                self.interrupt_buf.clear()
                self.INTERRUPT_COUNT = 0
                self.SILENCE_COUNTER = 0
                return

        # 3) æœªæ£€æµ‹åˆ°ç”¨æˆ·å‘å£°ï¼šSPEAK æŒç»­ï¼ˆç¦»çº¿ä¸æ¨¡æ‹Ÿæ’­æ”¾ç»“æŸï¼‰
        return


    async def run_realtime(self, websocket: WebSocket):
        await websocket.accept()
        print("âœ… å‰ç«¯å·²è¿žæŽ¥ï¼Œè¿›å…¥å®žæ—¶ä¼šè¯å¾ªçŽ¯")
        self.start_wall = time.time() #æ˜¯å¦è¦åˆå§‹åŒ–ï¼Ÿæ˜¯å¦éœ€è¦resetï¼Ÿ
        # self.MEDIA_TIME = 0.0
        # self.FRAME_IDX = 0

        try:
            while True:
                message = await websocket.receive()
                # message æ˜¯ dictï¼Œå½¢å¦‚ï¼š{"type": "websocket.receive", "bytes": b'...', "text": "..."}
                if message["type"] == "websocket.disconnect":
                    break

                if "text" in message:
                    text = message["text"]
                    obj = json.loads(text)
                    if obj.get("event") == "end":
                        print("å‰ç«¯ç»“æŸ")
                        # if self.IN_SPEECH and self.BUFFER:
                        #     await self.process_user_segment(self.BUFFER)
                        self.vad_iterator.reset_states()
                        self.reset()
                        continue
                    # å…¶ä»–æ–‡æœ¬æ¶ˆæ¯å¯é€‰å¤„ç†

                elif "bytes" in message:
                    raw_bytes = message["bytes"]
                    if len(raw_bytes) == 0:
                        continue
                    frame = np.frombuffer(raw_bytes, dtype=np.float32)
                    if frame.size == 0:
                        continue

                    # self.MEDIA_TIME += self.FRAME_SEC
                    self.FRAME_IDX += 1

                    event = self.detect_vad_frame(frame)
                    if event and ( "start" in event or "end" in event):
                        print(f"[Frame {self.FRAME_IDX}] VAD Event: {event}, STATE: {self.STATE}")
                    if self.STATE == "LISTEN":
                        await self.handle_listen(frame, event)
                    elif self.STATE == "SPEAK":
                        await self.handle_speak(frame, event)

        except WebSocketDisconnect:
            print("âš ï¸ WebSocket æ–­å¼€ï¼Œè‡ªåŠ¨æ¸…ç†çŠ¶æ€")
        except Exception as e:
            print(f"âŒ å®žæ—¶è¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()  # ðŸ‘ˆ å¼ºçƒˆå»ºè®®åŠ ä¸Šè¿™è¡Œï¼
        finally:
            self.vad_iterator.reset_states()
            self.reset()
            print("ä¼šè¯ç»“æŸï¼ŒçŠ¶æ€å·²æ¸…ç†")


# ============================================================
# FastAPI åº”ç”¨
# ============================================================

def create_app() -> FastAPI:
    app = FastAPI()
    @app.websocket("/realtime")
    async def realtime_ws(websocket: WebSocket):
        engine = ConversationEngine(websocket=websocket)
        await engine.run_realtime(websocket)
    return app


def main():
    parser = argparse.ArgumentParser(description="Realtime Voice WS Server")
    parser.add_argument("--host", default="0.0.0.0", help="Bind host")
    parser.add_argument("--port", type=int, default=18010, help="Bind port")
    parser.add_argument("--reload", action="store_true", help="Enable reload (dev)")
    args = parser.parse_args()

    app = create_app()
    uvicorn.run(app, host=args.host, port=args.port)

if __name__ == "__main__":
    main()