import os, json, asyncio, wave, time, torch, soundfile as sf, numpy as np
from pathlib import Path
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from silero_vad import load_silero_vad, VADIterator
from module import asr, llm_qwen3o, tts
import argparse
import uvicorn

# ============================================================
# ConversationEngine ï¼ˆä¸Žä½ çš„é€»è¾‘ä¸€è‡´ï¼ŒåªåŠ  websocket é€šçŸ¥èƒ½åŠ›ï¼‰
# ============================================================

class ConversationEngine:
    def __init__(self, sample_rate=16000, window_size=256, websocket: WebSocket = None):
        self.SAMPLE_RATE = sample_rate
        self.WINDOW_SIZE = window_size
        self.FRAME_SEC = window_size / sample_rate
        self.INTERRUPT_LIMIT = int(1.5 / self.FRAME_SEC)    #speakæ‰“æ–­ç¡¬æ—¶é—´ï¼Œå¯ä»¥æ”¹

        self.STATE = "LISTEN"
        self.IN_SPEECH = False
        self.BUFFER = []
        self.TURN_IDX = 0
        self.MEDIA_TIME = 0.0
        self.FRAME_IDX = 0
        self.CURRENT_TURN = None
        self.INTERRUPT_COUNT = 0
        self.FILE_NAME = "stream"
        self.END_HOLD_FRAMES = int(0.64 / self.FRAME_SEC)
        self.SILENCE_COUNTER = 0
        self.CONTINUE_INFER_TIMES = []
        self.AFTER_CONTINUE_SILENT_FRAMES = 0
        self.AFTER_CONTINUE_TIMEOUT_FRAMES = max(1, int(round(2.0 / self.FRAME_SEC)))
        self.CONTINUE_ARMED = False
        self.FROM_INTERRUPT = False
        self.history = []

        self.output_dir = Path("realtime_out")
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.vad_model = load_silero_vad()
        self.vad_iterator = VADIterator(self.vad_model, sampling_rate=self.SAMPLE_RATE)
        self.websocket = websocket  # âœ… ä¿å­˜ websocket å¼•ç”¨ç”¨äºŽäº‹ä»¶æŽ¨é€

    def reset(self):
        self.STATE = "LISTEN"
        self.TURN_IDX = 0
        self.MEDIA_TIME = 0.0
        self.FRAME_IDX = 0
        self.CURRENT_TURN = None
        self.BUFFER.clear()
        self.history.clear()
        self._vad_buf = np.zeros(0, dtype=np.float32)


    async def send_control(self, event_type: str, data=None):
        """å‘é€æŽ§åˆ¶äº‹ä»¶ç»™å‰ç«¯"""
        if not self.websocket:
            return
        payload = {"event": event_type, "data": data or {}}
        await self.websocket.send_text(json.dumps(payload))

    # ============= ä¸ŽåŽŸé€»è¾‘ä¸€è‡´çš„æ ¸å¿ƒå¤„ç†å‡½æ•° =============
    def detect_vad_frame(self, chunk):
        if not hasattr(self, "_vad_buf"):
            self._vad_buf = np.zeros(0, dtype=np.float32)
        self._vad_buf = np.concatenate([self._vad_buf, chunk])
        if len(self._vad_buf) >= 2 * self.WINDOW_SIZE:
            tensor = torch.from_numpy(self._vad_buf[: 2 * self.WINDOW_SIZE])
            event = self.vad_iterator(tensor, return_seconds=True)
            self._vad_buf = np.zeros(0, dtype=np.float32)
            return event
        return None

    async def process_user_segment(self, audio_buf):
        basename = self.output_dir.name
        turn_id = self.TURN_IDX

        
        user_audio = np.concatenate(audio_buf) if isinstance(audio_buf, list) else audio_buf

        # --- æž„å»ºä¸Šä¸‹æ–‡ prompt ---
        history_text = ""
        for turn in self.history[-3:]:
            role = "ç”¨æˆ·" if turn["role"] == "user" else "åŠ©æ‰‹"
            history_text += f"{role}:{turn['content']}\n"
        listen_prompt = f'''
        ä½ æ˜¯ä¸€ä¸ªè‡ªç„¶èŠå¤©çš„è¯­éŸ³åŠ©æ‰‹ï¼Œè¦åƒæœ‹å‹ä¸€æ ·å›žç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
        ä¸è¦åé—®ï¼Œä¹Ÿä¸è¦è§£é‡Šï¼Œä¸è¦è¾“å‡ºä»»ä½•æ ¼å¼è¯´æ˜Žã€‚
        {history_text}
        çŽ°åœ¨ï¼Œè¯·ç»§ç»­å›žåº”ç”¨æˆ·çš„æœ€æ–°è¯­éŸ³ï¼š
        '''
        api_start = time.perf_counter()
        decision = llm_qwen3o(listen_prompt, user_audio)
        api_time = time.perf_counter() - api_start

        # --- ASR ---
        tmp_path = self.output_dir / f"{self.FILE_NAME}_turn{self.TURN_IDX}_input.wav"
        sf.write(tmp_path, user_audio, self.SAMPLE_RATE)
        user_text = asr(str(tmp_path))
        self.history.append({"role": "user", "content": user_text})
        self.history.append({"role": "assistant", "content": decision})
        print(f"å†³ç­–ç»“æžœ: {decision}")

        
        if ("continue" not in decision.lower()) and ("ç»§ç»­" not in decision.lower()):
            tts_path = self.output_dir / f"{basename}_r{turn_id}.wav"
            tts_start = time.perf_counter()
            tts_file = tts(decision, tts_path)
            tts_time = time.perf_counter() - tts_start

            # âœ… å°† TTS éŸ³é¢‘å®žæ—¶å‘é€åˆ°å‰ç«¯
            with open(tts_file, "rb") as f:
                await self.websocket.send_bytes(f.read())
            await self.send_control("new_tts", {"turn": turn_id})

            audio_data, sr = sf.read(tts_file)
            tts_dur = len(audio_data) / sr
            sys_start = self.MEDIA_TIME + api_time + tts_time
            self.CURRENT_TURN = {
                "turn": turn_id,
                "user_end": round(self.MEDIA_TIME, 3),
                "api_time": round(api_time, 3),
                "tts_time": round(tts_time, 3),
                "tts_dur": round(tts_dur, 3),
                "sys_start": round(sys_start, 3),
                "tts_file": Path(tts_file).name
            }
            self.TURN_IDX += 1
            self.STATE = "SPEAK"
            self.IN_SPEECH = False
            self.BUFFER.clear()
        else:
            self.STATE = "LISTEN"
            self.IN_SPEECH = True

    # -------------------------------------------------------
    async def handle_listen(self, frame, event):
        """LISTEN çŠ¶æ€ï¼šæ£€æµ‹ç”¨æˆ·è¯­éŸ³ã€åˆ¤æ–­æ˜¯å¦è¯´å®Œã€å†³å®šæ˜¯å¦è¿›å…¥ SPEAK"""
        # --- 1. ç”¨æˆ·å¼€å§‹è¯´è¯ ---
        if event and "start" in event and not self.IN_SPEECH:
            self.IN_SPEECH = True
            self.BUFFER = [frame]
            return
        # --- 2. ç”¨æˆ·æ­£åœ¨è¯´è¯ ---
        if not self.IN_SPEECH:
            return  # ç”¨æˆ·æœªå‘è¨€ï¼Œç›´æŽ¥è·³è¿‡æœ¬å¸§

        self.BUFFER.append(frame)

        # --- 3. æ£€æµ‹è¯­éŸ³ç»“æŸ ---
        if event and "end" in event:
            self.SILENCE_COUNTER = 1
            # self.process_user_segment(self.BUFFER)
            return

        if self.SILENCE_COUNTER > 0:
        # å¦‚æžœåœ¨é™éŸ³æœŸé—´å‡ºçŽ°æ–°çš„ startï¼Œåˆ™ç»§ç»­æŽ¥ä¸Š buffer
            if event and "start" in event:
                self.SILENCE_COUNTER = 0
                return
            else:
                self.SILENCE_COUNTER += 1
                # è¾¾åˆ° 640 msï¼ˆEND_HOLD_FRAMESï¼‰åŽï¼Œç¡®è®¤ç»“æŸ
                if self.SILENCE_COUNTER >= self.END_HOLD_FRAMES:
                    self.SILENCE_COUNTER = 0

                    # === æ–°å¢žé˜¶æ®µä¸€åˆ¤æ–­ ===
                    user_audio = np.concatenate(self.BUFFER)
                    judge_prompt = (
                        "ä½ éœ€è¦ä»Žæ—¥å¸¸å¯¹è¯çš„è§’åº¦,è€Œä¸æ˜¯è¯­æ³•çš„è§’åº¦åŽ»åˆ¤æ–­è¿™å¥è¯æ˜¯å¦è¯´å®Œäº†ã€‚"
                        "é¦–å…ˆï¼Œå¦‚æžœä½ è®¤ä¸ºç”¨æˆ·è¿™å¥è¯æ˜Žæ˜¾æ²¡æœ‰è¯´å®Œï¼Œè¯·åªè¾“å‡ºå­—ç¬¦ä¸²'continue'ã€‚"
                        "å¦‚æžœä½ è®¤ä¸ºç”¨æˆ·å·²ç»è¯´å®Œï¼Œè¯·åªè¾“å‡ºå­—ç¬¦ä¸²'end'ã€‚ä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"
                    )

                    start_time = time.time()
                    judge_result = llm_qwen3o(judge_prompt, user_audio).strip().lower()
                    infer_time = time.time() - start_time
                    self.CONTINUE_INFER_TIMES.append(infer_time)

                    print(f"ç”¨æˆ·è¯­éŸ³å®Œæ•´æ€§åˆ¤å®š: {judge_result}")
                    if "continue" in judge_result:
                        self.CONTINUE_ARMED = True
                        prefill = int(round(infer_time / self.FRAME_SEC))
                        self.AFTER_CONTINUE_SILENT_FRAMES = prefill
                        print("ðŸ” ç”¨æˆ·æœªè¯´å®Œï¼Œç»§ç»­ç´¯ç§¯å¸§")
                        self.IN_SPEECH = True
                        return

                    # === è¯´å®Œäº†ï¼Œè¿›å…¥å®Œæ•´æµç¨‹ ===
                    await self.process_user_segment(self.BUFFER)
                    return

        # --- ä»…åœ¨ä¸Šä¸€æ¬¡åˆ¤å®šä¸º continue ä¸”å·²æ­¦è£…æ—¶æ‰è®¡æ•° ---
        if self.CONTINUE_ARMED:
            if not event:
                # æ— äº‹ä»¶å¸§ï¼šç´¯åŠ ç©ºç™½å¸§
                self.AFTER_CONTINUE_SILENT_FRAMES += 1

                # è®¡ç®—è§¦å‘é˜ˆå€¼ = 2s å¯¹åº”å¸§æ•° + æœ¬æ¬¡æŽ¨ç†è€—æ—¶æŠ˜ç®—çš„å¸§æ•°
                last_infer = self.CONTINUE_INFER_TIMES[-1] if self.CONTINUE_INFER_TIMES else 0.0
                infer_frames = int(round(last_infer / self.FRAME_SEC))
                trigger_frames = self.AFTER_CONTINUE_TIMEOUT_FRAMES + infer_frames

                # æ»¡è¶³æ¡ä»¶ï¼šç©ºç™½å¸§æ•°è¶…è¿‡ (2s + æŽ¨ç†è€—æ—¶)
                if self.AFTER_CONTINUE_SILENT_FRAMES >= trigger_frames:
                    print(
                        f"âš ï¸ continue åŽç©ºç™½ç´¯è®¡ {self.AFTER_CONTINUE_SILENT_FRAMES} å¸§ "
                        f"(é˜ˆå€¼ {trigger_frames} å¸§ â‰ˆ 2s+{last_infer:.3f}s)ï¼Œå¼ºåˆ¶å¤„ç†"
                    )
                    await self.process_user_segment(self.BUFFER)
                    # æ¸…ç†çŠ¶æ€
                    self.CONTINUE_INFER_TIMES.clear()
                    self.CONTINUE_ARMED = False
                    self.AFTER_CONTINUE_SILENT_FRAMES = 0
                    self.IN_SPEECH = False
                    self.BUFFER.clear()
                    return
            else:
                # ä»»æ„äº‹ä»¶ï¼ˆstart / endï¼‰æ‰“æ–­ç©ºç™½ â†’ è§£é™¤æ­¦è£…å¹¶æ¸…é›¶
                self.CONTINUE_ARMED = False
                self.AFTER_CONTINUE_SILENT_FRAMES = 0


    async def handle_speak(self, frame, event):
        """SPEAK çŠ¶æ€ï¼šæ£€æµ‹çŸ­æ‰“æ–­æˆ–é•¿æ‰“æ–­"""
        if event and "start" in event and not self.IN_SPEECH:
            self.IN_SPEECH = True
            self.interrupt_buf = [frame]
            self.INTERRUPT_COUNT = 1
            self.SILENCE_COUNTER = 0
            return

        if self.IN_SPEECH:
            self.interrupt_buf.append(frame)
            self.INTERRUPT_COUNT += 1

            # --- æ£€æµ‹åˆ°ç”¨æˆ·ç»“æŸè®²è¯ ---
            if event and "end" in event:
                self.SILENCE_COUNTER = 1
                return

            # --- é™éŸ³ç¡®è®¤é˜¶æ®µï¼ˆ640 ms å»¶è¿Ÿï¼‰---
            if self.SILENCE_COUNTER > 0:
                if event and "start" in event:
                    # 640ms å†…å‡ºçŽ°æ–°è¯­éŸ³ â†’ ç»§ç»­æŽ¥ä¸Š
                    self.SILENCE_COUNTER = 0
                    return
                else:
                    self.SILENCE_COUNTER += 1
                    if self.SILENCE_COUNTER >= self.END_HOLD_FRAMES:
                        # âœ… ç¡®è®¤æ‰“æ–­ç»“æŸ
                        seg_audio = np.concatenate(self.interrupt_buf)
                        speak_prompt = (
                            "ä½ çŽ°åœ¨å¤„äºŽ SPEAK çŠ¶æ€ï¼Œç”¨æˆ·åˆšæ‰åœ¨ä½ è¯´è¯æ—¶å‘å‡ºäº†ä¸€æ®µè¯­éŸ³ã€‚"
                            "è¯·æ ¹æ®è¯­ä¹‰åˆ¤æ–­ä»–æ˜¯å¦çœŸçš„æƒ³æ‰“æ–­ä½ ã€‚"
                            "å¦‚æžœæ˜¯æ˜Žç¡®çš„åé©³ã€å¦å®šã€æå‡ºé—®é¢˜ã€è¦æ±‚åœæ­¢ã€è¦æ±‚æ›´æ­£ç­‰ï¼Œè¿”å›ž 'interrupt'ï¼›"
                            "å¦‚æžœåªæ˜¯é™„å’Œã€å›žåº”ã€èµžåŒæˆ–é¼“åŠ±ï¼ˆä¾‹å¦‚â€œå¥½çš„â€â€œçŸ¥é“äº†â€â€œè¯´å¾—å¥½â€â€œå—¯å—¯â€â€œè¡Œâ€ï¼‰ï¼Œ"
                            "è¯·è¿”å›ž 'continue'ã€‚"
                            "ä½ åªèƒ½è¿”å›žè¿™ä¸¤ä¸ªå•è¯ä¹‹ä¸€ã€‚ä¸è¦è§£é‡Šã€ä¸è¦è¾“å‡ºå…¶å®ƒå†…å®¹ã€‚\n\n"

                            "ä»¥ä¸‹æ˜¯ä¸€äº›ç¤ºä¾‹ï¼š\n"
                            "ç”¨æˆ·ï¼šçŸ¥é“äº†ã€‚\nåŠ©æ‰‹ï¼šcontinue\n"
                            "ç”¨æˆ·ï¼šå¥½å¾—å¾ˆã€‚\nåŠ©æ‰‹ï¼šcontinue\n"
                            "ç”¨æˆ·ï¼šä½ è¯´å¾—çœŸæ£’ã€‚\nåŠ©æ‰‹ï¼šcontinue\n"
                            "ç”¨æˆ·ï¼šå—¯å—¯ï¼Œå¯¹ã€‚\nåŠ©æ‰‹ï¼šcontinue\n"
                            "ç”¨æˆ·ï¼šæˆ‘ä¸åŒæ„ä½ è¯´çš„ã€‚\nåŠ©æ‰‹ï¼šinterrupt\n"
                            "ç”¨æˆ·ï¼šä¸æ˜¯è¿™æ ·çš„ã€‚\nåŠ©æ‰‹ï¼šinterrupt\n"
                            "ç”¨æˆ·ï¼šä½ åˆ«è¯´äº†ã€‚\nåŠ©æ‰‹ï¼šinterrupt\n"
                            "ç”¨æˆ·ï¼šç­‰ä¸€ä¸‹ã€‚\nåŠ©æ‰‹ï¼šinterrupt\n\n"

                            "çŽ°åœ¨è¯·åˆ¤æ–­å½“å‰ç”¨æˆ·è¿™æ®µè¯­éŸ³çš„ç±»åž‹ï¼Œåªè¿”å›ž 'interrupt' æˆ– 'continue'ï¼š"
                        )
                        intent = llm_qwen3o(speak_prompt, seg_audio)
                        print(f"å‡ºçŽ°äº†æ‰“æ–­ï¼Œæ‰“æ–­æ„å›¾åˆ¤å®š: {intent}")

                        if "interrupt" in intent.lower():
                            # âœ…ã€å‰ç«¯ä¿¡å·ã€‘çŸ­æ‰“æ–­ï¼šåº”ç«‹å³åœæ­¢å½“å‰ TTS æ’­æ”¾
                            await self.send_control("stop_audio", {"reason": "short_semantic_interrupt"})

                            # è¿™ä¸€å¥åº”è¯¥ä¼ é€’åˆ°å‰ç«¯
                            self.CURRENT_TURN.setdefault("speak", {})["interrupt_time"] = round(self.MEDIA_TIME, 2)
                            # ä¸éœ€è¦å†™jsonï¼Œè€Œæ˜¯å‘é€åˆ°å‰ç«¯
                            # self.STATE = "LISTEN"
                            self.BUFFER = self.interrupt_buf.copy()
                            print("ðŸ” æ£€æµ‹åˆ°çŸ­æ‰“æ–­ï¼Œå¯åŠ¨æ–°ä¸€è½® listenâ†’speak")
                            await self.process_user_segment(self.BUFFER)

                            # æ¸…ç†çŠ¶æ€
                            self.IN_SPEECH = False
                            self.interrupt_buf.clear()
                            self.INTERRUPT_COUNT = 0
                            self.SILENCE_COUNTER = 0
                            return

                        else:
                            # âŒ backchannel / ç»§ç»­è¯´ï¼šå¿½ç•¥æ‰“æ–­ï¼Œä¿æŒSPEAK
                            self.IN_SPEECH = False
                            self.interrupt_buf.clear()
                            self.INTERRUPT_COUNT = 0
                            self.SILENCE_COUNTER = 0
                            # ä¸åˆ‡æ¢ stateï¼Œç»§ç»­ SPEAK
                            return
            # 2.2 é•¿æ‰“æ–­ï¼šç´¯è®¡è¾¾åˆ°/è¶…è¿‡ 1.5sï¼Œæ— éœ€ç­‰å¾… endï¼Œç›´æŽ¥åˆ‡ LISTEN
            if self.SILENCE_COUNTER == 0 and self.INTERRUPT_COUNT >= self.INTERRUPT_LIMIT:
                print("âœ…å‡ºçŽ°é•¿æ‰“æ–­ï¼Œåˆ‡æ¢åˆ°listenç»§ç»­å¬ï¼Œæ­£ç¡®å¼€å¯ç¬¬äºŒè½®")
                # âœ…ã€å‰ç«¯ä¿¡å·ã€‘é•¿æ‰“æ–­ï¼šåº”ç«‹å³åœæ­¢å½“å‰ TTS æ’­æ”¾
                await self.send_control("stop_audio", {"reason": "long_interrupt"})

                self.CURRENT_TURN.setdefault("speak", {})["interrupt_time"] = round(self.MEDIA_TIME, 2)
                self.STATE = "LISTEN"
                self.BUFFER = self.interrupt_buf.copy()  # äº¤ç»™ä¸‹ä¸€è½®ç»§ç»­ç´¯è®¡
                self.IN_SPEECH = True
                self.interrupt_buf.clear()
                self.INTERRUPT_COUNT = 0
                return

        # 3) æœªæ£€æµ‹åˆ°ç”¨æˆ·å‘å£°ï¼šSPEAK æŒç»­ï¼ˆç¦»çº¿ä¸æ¨¡æ‹Ÿæ’­æ”¾ç»“æŸï¼‰
        return


    async def run_realtime(self, websocket: WebSocket):
        await websocket.accept()
        print("âœ… å‰ç«¯å·²è¿žæŽ¥ï¼Œè¿›å…¥å®žæ—¶ä¼šè¯å¾ªçŽ¯")

        self.MEDIA_TIME = 0.0
        self.FRAME_IDX = 0

        try:
            while True:
                message = await websocket.receive()
                # message æ˜¯ dictï¼Œå½¢å¦‚ï¼š{"type": "websocket.receive", "bytes": b'...', "text": "..."}
                if message["type"] == "websocket.disconnect":
                    break

                if "text" in message:
                    text = message["text"]
                    obj = json.loads(text)
                    if obj.get("event") == "end":
                        print("å‰ç«¯ç»“æŸ")
                        if self.IN_SPEECH and self.BUFFER:
                            await self.process_user_segment(self.BUFFER)
                        self.vad_iterator.reset_states()
                        self.reset()
                        continue
                    # å…¶ä»–æ–‡æœ¬æ¶ˆæ¯å¯é€‰å¤„ç†

                elif "bytes" in message:
                    raw_bytes = message["bytes"]
                    if len(raw_bytes) == 0:
                        continue
                    frame = np.frombuffer(raw_bytes, dtype=np.float32)
                    if frame.size == 0:
                        continue

                    self.MEDIA_TIME += self.FRAME_SEC
                    self.FRAME_IDX += 1

                    event = self.detect_vad_frame(frame)
                    if self.STATE == "LISTEN":
                        await self.handle_listen(frame, event)
                    elif self.STATE == "SPEAK":
                        await self.handle_speak(frame, event)

        except WebSocketDisconnect:
            print("âš ï¸ WebSocket æ–­å¼€ï¼Œè‡ªåŠ¨æ¸…ç†çŠ¶æ€")
        except Exception as e:
            print(f"âŒ å®žæ—¶è¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()  # ðŸ‘ˆ å¼ºçƒˆå»ºè®®åŠ ä¸Šè¿™è¡Œï¼
        finally:
            self.vad_iterator.reset_states()
            self.reset()
            print("ä¼šè¯ç»“æŸï¼ŒçŠ¶æ€å·²æ¸…ç†")


# ============================================================
# FastAPI åº”ç”¨
# ============================================================

def create_app() -> FastAPI:
    app = FastAPI()
    @app.websocket("/realtime")
    async def realtime_ws(websocket: WebSocket):
        engine = ConversationEngine(websocket=websocket)
        await engine.run_realtime(websocket)
    return app


def main():
    parser = argparse.ArgumentParser(description="Realtime Voice WS Server")
    parser.add_argument("--host", default="0.0.0.0", help="Bind host")
    parser.add_argument("--port", type=int, default=18000, help="Bind port")
    parser.add_argument("--reload", action="store_true", help="Enable reload (dev)")
    args = parser.parse_args()

    app = create_app()
    uvicorn.run(app, host=args.host, port=args.port)

if __name__ == "__main__":
    main()