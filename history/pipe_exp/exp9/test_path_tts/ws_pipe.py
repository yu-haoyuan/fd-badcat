import json, asyncio, time, torch, soundfile as sf, numpy as np
from pathlib import Path
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from silero_vad import load_silero_vad, VADIterator
from module import asr, llm_qwen3o, tts
import argparse
import uvicorn
from datetime import datetime
import yaml

# ============================================================
# ConversationEngine ï¼ˆä¸ä½ çš„é€»è¾‘ä¸€è‡´ï¼ŒåªåŠ  websocket é€šçŸ¥èƒ½åŠ›ï¼‰
# ============================================================

class ConversationEngine:
    def __init__(self, websocket: WebSocket = None, prompts: dict = None, delay: dict = None):

        self.SAMPLE_RATE = 16000
        self.WINDOW_SIZE = 256
        self.FRAME_SEC = 256 / 16000 # 256/16000 = 0.016

        self.STATE = "LISTEN"
        self.IN_SPEECH = False
        self.BUFFER = []
        self.TURN_IDX = 0
        self.FRAME_IDX = 0
        self.CURRENT_TURN = None
        self.INTERRUPT_COUNT = 0

        #yaml
        self.prompts = prompts
        self.delay = delay
        self.END_HOLD_FRAMES = float(delay["end_hold_frame"]) # 0.64
        self.AFTER_CONTINUE_TIMEOUT_FRAMES = float(delay["after_continue_time"]) # 2


        self.SILENCE_COUNTER = 0
        self.CONTINUE_INFER_TIMES = []
        self.CONTINUE_START_TIME = None

        self.CONTINUE_ARMED = False
        self.FROM_INTERRUPT = False
        self.history = []
        self.interrupt_buf = []
        self.INTERRUPT_START_TIME = 0

        self.output_dir = None

        self.vad_model = load_silero_vad()
        self.vad_iterator = VADIterator(self.vad_model, sampling_rate=self.SAMPLE_RATE)
        self.websocket = websocket  # âœ… ä¿å­˜ websocket å¼•ç”¨ç”¨äºäº‹ä»¶æ¨é€

        #prompt
        self.JUDGE_PROMPT = prompts.get("judge", None)
        self.INTERRUPT_PROMPT = prompts.get("interrupt", None)


    def build_res_prompt(self):
        """åŠ¨æ€æ„é€ RES_PROMPTï¼ŒåŒ…å«æœ€æ–°history"""
        base = self.prompts.get("response_template", None)
        if base:
            base = base.replace("{history}", json.dumps(self.history, ensure_ascii=False))
            return base
        else:
            return (
                "ä½ æ˜¯ä¸€ä¸ªè‡ªç„¶èŠå¤©çš„è¯­éŸ³åŠ©æ‰‹ï¼Œè¦åƒæœ‹å‹ä¸€æ ·å›ç­”ç”¨æˆ·çš„é—®é¢˜\n"
                "ä¸è¦åé—®ï¼Œä¹Ÿä¸è¦è§£é‡Šï¼Œä¸è¦è¾“å‡ºä»»ä½•æ ¼å¼è¯´æ˜ï¼Œå¿…é¡»æ ¹æ®ä½ å¬åˆ°çš„è¯­è¨€å›ç­”å¯¹åº”çš„è¯­è¨€ï¼Œåªæœ‰ä¸­æ–‡orè‹±æ–‡\n"
                f"åªæœ‰ç”¨æˆ·æåˆ°â€œé‡å¤â€â€œé‡æ–°â€ï¼Œæ‰éœ€è¦å‚è€ƒå†å²ä¿¡æ¯{self.history}è¿›è¡Œé‡å¤å›ç­”ï¼Œå¦åˆ™ä¸è¦å…³æ³¨å†å²ä¿¡æ¯\n"
                "å¦‚æœç”¨æˆ·æåˆ°â€œå¦‚æœâ€â€œæ€ä¹ˆåŠâ€â€œä¸è¡Œâ€ç­‰å‡è®¾æ€§æˆ–å¦å®šæ€§å†…å®¹ï¼Œè¯·å›ç­”å½“ä¸‹é—®é¢˜ï¼Œä¸è¦å‚è€ƒå†å²ä¿¡æ¯ã€‚"
                "ä»¥ä¸‹æ˜¯ç”¨æˆ·åˆšæ‰è¯´çš„è¯ï¼Œè¯·ä½ è¿›è¡Œå›åº”ï¼š"
            )

    def reset(self):
        self.STATE = "LISTEN"
        self.TURN_IDX = 0
        # self.MEDIA_TIME = 0.0
        self.FRAME_IDX = 0
        self.CURRENT_TURN = None
        self.BUFFER.clear()
        self.history.clear()
        self._vad_buf = np.zeros(0, dtype=np.float32)
        self.IN_SPEECH = False
        self.SILENCE_COUNTER = 0
        self.CONTINUE_ARMED = False
        self.CONTINUE_START_TIME = None
        self.INTERRUPT_COUNT = 0
        self.FROM_INTERRUPT = False
        self.interrupt_buf.clear()




    async def send_control(self, event_type: str, data=None):
        """å‘é€æ§åˆ¶äº‹ä»¶ç»™å‰ç«¯"""
        if not self.websocket:
            return
        payload = {"event": event_type, "data": data or {}}
        await self.websocket.send_text(json.dumps(payload))  

    # ============= ä¸åŸé€»è¾‘ä¸€è‡´çš„æ ¸å¿ƒå¤„ç†å‡½æ•° =============
    def detect_vad_frame(self, chunk):
        if not hasattr(self, "_vad_buf"):
            self._vad_buf = np.zeros(0, dtype=np.float32)
        self._vad_buf = np.concatenate([self._vad_buf, chunk])
        if len(self._vad_buf) >= 2 * self.WINDOW_SIZE:
            tensor = torch.from_numpy(self._vad_buf[: 2 * self.WINDOW_SIZE])
            event = self.vad_iterator(tensor, return_seconds=True)
            self._vad_buf = np.zeros(0, dtype=np.float32)
            return event
        return None

    async def async_asr(self, user_audio, turn_id):
        """å¼‚æ­¥ASRä»»åŠ¡ï¼šä»…åšæ–‡æœ¬è½¬å†™ä¸å†å²æ›´æ–°ï¼Œä¸å‚ä¸å½“å‰é€»è¾‘"""
        tmp = self.output_dir / f"stream_turn{turn_id}_input.wav"
        sf.write(tmp, user_audio, self.SAMPLE_RATE)
        user_text = await asyncio.to_thread(asr, str(tmp))
        await self.send_control("asr_done", {
            "turn": turn_id,
            "state": self.STATE,
            "text": user_text,
            "timestamp": round(time.time() - self.start_wall, 3)
        })
        self.history.append({"role": "user", "content": user_text})
        # await self.send_control("context", {"turn":self.history,"timestamp": round(time.time() - self.start_wall, 3)})
        self.BUFFER.clear()
        return user_text

    async def async_llm(self, prompt, user_audio, turn_id, add_to_history: bool = False):
        start_t = time.perf_counter()
        decision = await asyncio.to_thread(llm_qwen3o, prompt, user_audio)
        infer_time = round(time.perf_counter() - start_t, 3)

        await self.send_control("llm_done", {
            "turn": turn_id,
            "state": self.STATE,
            "content": decision,
            "timestamp": round(time.time() - self.start_wall, 3),
            "infer_time": infer_time
        })
        if add_to_history:
            self.history.append({"role": "assistant", "content": decision})
        self.IN_SPEECH = False
        return decision

    async def async_tts(self, text, turn_id):
        tts_path = self.output_dir / f"turn{turn_id}_tts.wav"
        tts_file = await asyncio.to_thread(tts, text, tts_path)
        await self.send_control("tts_done", {"turn": turn_id,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
        with open(tts_file, "rb") as f:
            await self.websocket.send_bytes(f.read())

        self.STATE = "SPEAK"


    # -------------------------------------------------------
    async def handle_listen(self, frame, event):
        """LISTEN çŠ¶æ€ï¼šæ£€æµ‹ç”¨æˆ·è¯­éŸ³ã€åˆ¤æ–­æ˜¯å¦è¯´å®Œã€å†³å®šæ˜¯å¦è¿›å…¥ SPEAK"""
        # --- 1. ç”¨æˆ·å¼€å§‹è¯´è¯ ---
        if event and "start" in event and not self.IN_SPEECH:
            await self.send_control("vad_start", {"turn": self.TURN_IDX,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
            self.IN_SPEECH = True
            self.BUFFER = [frame]
            return
        # --- 2. ç”¨æˆ·æ­£åœ¨è¯´è¯ ---
        if not self.IN_SPEECH:
            return  # ç”¨æˆ·æœªå‘è¨€ï¼Œç›´æ¥è·³è¿‡æœ¬å¸§

        self.BUFFER.append(frame)

        # --- 3. æ£€æµ‹è¯­éŸ³ç»“æŸ ---
        if event and "end" in event:
            self.SILENCE_COUNTER = 1
            self.INTERRUPT_END_TIME = time.time()
            await self.send_control("vad_done", {"turn": self.TURN_IDX,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
            return

        if self.SILENCE_COUNTER > 0:
        # å¦‚æœåœ¨é™éŸ³æœŸé—´å‡ºç°æ–°çš„ startï¼Œåˆ™ç»§ç»­æ¥ä¸Š buffer
            if event and "start" in event:
                self.SILENCE_COUNTER = 0
                return
            else:
                elapsed_silence = time.time() - self.INTERRUPT_END_TIME
                # è¾¾åˆ° 640 msï¼ˆEND_HOLD_FRAMESï¼‰åï¼Œç¡®è®¤ç»“æŸ
                if elapsed_silence >= self.END_HOLD_FRAMES:
                    self.SILENCE_COUNTER = 0

                    # === æ–°å¢é˜¶æ®µä¸€åˆ¤æ–­ ===
                    await self.send_control("vad_640_done", {"turn": self.TURN_IDX,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
                    user_audio = np.concatenate(self.BUFFER)
                    decision = await self.async_llm(self.JUDGE_PROMPT, user_audio, self.TURN_IDX, add_to_history=False)
                    if "continue" in decision.lower():
                        self.CONTINUE_ARMED = True
                        self.CONTINUE_START_TIME = time.time()
                        self.IN_SPEECH = True
                        return

                    # === è¯´å®Œäº†ï¼Œè¿›å…¥å®Œæ•´æµç¨‹ ===
                    asyncio.create_task(self.async_asr(user_audio, self.TURN_IDX))
                    prompt_res_1 = self.build_res_prompt()
                    await self.send_control("prompt_lis", {"p": prompt_res_1,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
                    decision = await self.async_llm(prompt_res_1, user_audio, self.TURN_IDX, add_to_history=True)
                    asyncio.create_task(self.async_tts(decision, self.TURN_IDX))
                    
                    return

        # --- ä»…åœ¨ä¸Šä¸€æ¬¡åˆ¤å®šä¸º continue ä¸”å·²æ­¦è£…æ—¶æ‰è®¡æ•° ---
        if self.CONTINUE_ARMED:
            # æ£€æŸ¥å½“å‰æ˜¯å¦è¶…æ—¶
            elapsed = time.time() - self.CONTINUE_START_TIME
            if elapsed >= self.AFTER_CONTINUE_TIMEOUT_FRAMES:  # è¶…è¿‡2ç§’æ²¡æ–°è¯­éŸ³å°±å¼ºåˆ¶å¤„ç†
                # è°ƒç”¨å®Œæ•´å“åº”é€»è¾‘
                user_audio = np.concatenate(self.BUFFER)
                asyncio.create_task(self.async_asr(user_audio, self.TURN_IDX))
                prompt_res_2 = self.build_res_prompt()
                await self.send_control("prompt_lis", {"p": prompt_res_2,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
                decision = await self.async_llm(prompt_res_2, user_audio, self.TURN_IDX, add_to_history=True)
                asyncio.create_task(self.async_tts(decision, self.TURN_IDX))

                # æ¸…ç†çŠ¶æ€
                self.CONTINUE_ARMED = False
                self.CONTINUE_START_TIME = None
                self.IN_SPEECH = False
                self.BUFFER.clear()
                return

            # å¦‚æœå‡ºç°æ–°è¯­éŸ³äº‹ä»¶ï¼Œåˆ™é‡ç½®
            if event and "start" in event:
                self.CONTINUE_ARMED = False
                self.CONTINUE_START_TIME = None


    async def handle_speak(self, frame, event):
        """SPEAK çŠ¶æ€ï¼šæ£€æµ‹çŸ­æ‰“æ–­æˆ–é•¿æ‰“æ–­"""
        if event and "start" in event and not self.IN_SPEECH:
            await self.send_control("vad_start", {"turn": self.TURN_IDX,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
            self.IN_SPEECH = True
            self.interrupt_buf = [frame]
            self.INTERRUPT_COUNT = 1
            self.SILENCE_COUNTER = 0
            self.INTERRUPT_START_TIME = time.time() 
            return

        if self.IN_SPEECH:
            self.interrupt_buf.append(frame)
            self.INTERRUPT_COUNT += 1

            # --- 2.1 æ£€æµ‹ç”¨æˆ·ç»“æŸè®²è¯ï¼ˆendäº‹ä»¶ï¼‰---
            if event and "end" in event:
                self.SILENCE_COUNTER = 1
                await self.send_control("vad_done", {"turn": self.TURN_IDX,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
                self.INTERRUPT_END_TIME = time.time()
                return

            # --- é™éŸ³ç¡®è®¤é˜¶æ®µï¼ˆ640 ms å»¶è¿Ÿï¼‰---
            if self.SILENCE_COUNTER > 0:
                if event and "start" in event: # 640ms å†…å‡ºç°æ–°è¯­éŸ³ â†’ ç»§ç»­æ¥ä¸Š
                    self.SILENCE_COUNTER = 0
                    return
                else:
                    elapsed_silence = time.time() - self.INTERRUPT_END_TIME   # ç”¨çœŸå®æ—¶é—´åˆ¤æ–­é™éŸ³
                    if elapsed_silence >= self.END_HOLD_FRAMES:  # è¶…è¿‡640msï¼Œè®¤ä¸ºæ‰“æ–­ç»“æŸ
                        seg_audio = np.concatenate(self.interrupt_buf)
                        intent = await self.async_llm(self.INTERRUPT_PROMPT, seg_audio, self.TURN_IDX, add_to_history=False)
                        # print(f"å‡ºç°äº†æ‰“æ–­ï¼Œæ‰“æ–­æ„å›¾åˆ¤å®š: {intent}")

                        if "interrupt" in intent.lower():
                            await self.send_control("shot_interrupt", {"turn": self.TURN_IDX,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
                            self.BUFFER = self.interrupt_buf.copy()
                            self.TURN_IDX += 1
                            user_audio = np.concatenate(self.interrupt_buf)
                            asyncio.create_task(self.async_asr(user_audio, self.TURN_IDX))
                            prompt_res_3 = self.build_res_prompt()
                            await self.send_control("prompt_inter", {"p": prompt_res_3,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
                            decision = await self.async_llm(prompt_res_3, user_audio, self.TURN_IDX, add_to_history=True)
                            asyncio.create_task(self.async_tts(decision, self.TURN_IDX))

                            # æ¸…ç†çŠ¶æ€
                            self.IN_SPEECH = False
                            self.interrupt_buf.clear()
                            self.INTERRUPT_COUNT = 0
                            self.SILENCE_COUNTER = 0
                            return

                        else:
                            await self.send_control("no_interrupt", {"turn": self.TURN_IDX,"state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
                            self.IN_SPEECH = False
                            self.interrupt_buf.clear()
                            self.INTERRUPT_COUNT = 0
                            self.SILENCE_COUNTER = 0
                            # ä¸åˆ‡æ¢ stateï¼Œç»§ç»­ SPEAK
                            return
            # 2.2 é•¿æ‰“æ–­ï¼šåªæœ‰æ²¡æœ‰å‡ºç°endçš„æ—¶å€™ï¼Œä¹Ÿå°±æ˜¯self.SILENCE_COUNTER == 0
            # ç„¶åå¿…é¡»è¦bufferé‡Œé¢æœ‰ä¸œè¥¿
            #ç´¯è®¡è¾¾åˆ°/è¶…è¿‡ 1.5sï¼Œæ— éœ€ç­‰å¾… endï¼Œç›´æ¥åˆ‡ LISTEN
            if (self.interrupt_buf and 
                self.SILENCE_COUNTER == 0 and
                time.time() - self.INTERRUPT_START_TIME >= 1.5):
                self.TURN_IDX += 1
                
                self.STATE = "LISTEN"
                await self.send_control("long_interrupt", {"turn": self.TURN_IDX, "state": self.STATE, "timestamp": round(time.time() - self.start_wall, 3)})
                self.BUFFER = self.interrupt_buf.copy()  # äº¤ç»™ä¸‹ä¸€è½®ç»§ç»­ç´¯è®¡
                self.IN_SPEECH = True
                self.interrupt_buf.clear()
                self.INTERRUPT_COUNT = 0
                self.SILENCE_COUNTER = 0
                return

        # 3) æœªæ£€æµ‹åˆ°ç”¨æˆ·å‘å£°ï¼šSPEAK æŒç»­ï¼ˆç¦»çº¿ä¸æ¨¡æ‹Ÿæ’­æ”¾ç»“æŸï¼‰
        return


    async def run_realtime(self, websocket: WebSocket):
        # await websocket.accept()
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{now}] âœ… å‰ç«¯å·²è¿æ¥ï¼Œè¿›å…¥å®æ—¶ä¼šè¯å¾ªç¯")
        self.start_wall = time.time() #æ˜¯å¦è¦åˆå§‹åŒ–ï¼Ÿæ˜¯å¦éœ€è¦resetï¼Ÿ
        # self.MEDIA_TIME = 0.0
        # self.FRAME_IDX = 0

        try:
            while True:
                message = await websocket.receive()
                # message æ˜¯ dictï¼Œå½¢å¦‚ï¼š{"type": "websocket.receive", "bytes": b'...', "text": "..."}
                if message["type"] == "websocket.disconnect":
                    break

                if "text" in message:
                    text = message["text"]
                    obj = json.loads(text)
                    if obj.get("event") == "end":
                        print("å‰ç«¯ç»“æŸ")
                        # if self.IN_SPEECH and self.BUFFER:
                        #     await self.process_user_segment(self.BUFFER)
                        self.vad_iterator.reset_states()
                        self.reset()
                        continue
                    # å…¶ä»–æ–‡æœ¬æ¶ˆæ¯å¯é€‰å¤„ç†

                elif "bytes" in message:
                    raw_bytes = message["bytes"]
                    if len(raw_bytes) == 0:
                        continue
                    frame = np.frombuffer(raw_bytes, dtype=np.float32)
                    if frame.size == 0:
                        continue
                    self.FRAME_IDX += 1

                    event = self.detect_vad_frame(frame)
                    # if event and ( "start" in event or "end" in event):
                    #     print(f"[Frame {self.FRAME_IDX}] VAD Event: {event}, STATE: {self.STATE}")
                    if self.STATE == "LISTEN":
                        await self.handle_listen(frame, event)
                    elif self.STATE == "SPEAK":
                        await self.handle_speak(frame, event)

        except WebSocketDisconnect:
            print("âš ï¸ WebSocket æ–­å¼€ï¼Œè‡ªåŠ¨æ¸…ç†çŠ¶æ€")
        except Exception as e:
            print(f"âŒ å®æ—¶è¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()  # ğŸ‘ˆ å¼ºçƒˆå»ºè®®åŠ ä¸Šè¿™è¡Œï¼
        finally:
            self.vad_iterator.reset_states()
            self.reset()
            print("ä¼šè¯ç»“æŸï¼ŒçŠ¶æ€å·²æ¸…ç†")


# ============================================================
# FastAPI åº”ç”¨
# ============================================================

def create_app(prompts: dict, delay: dict) -> FastAPI:
    app = FastAPI()
    @app.websocket("/realtime")
    async def realtime_ws(websocket: WebSocket):
        # âœ… æŠŠ prompts ä¼ ç»™ ConversationEngine
        await websocket.accept()
        msg = await websocket.receive_json()
        data = msg.get("data", {})
        exp = data.get("exp", {})
        lang = data.get("lang", {})

        engine = ConversationEngine(websocket=websocket, prompts=prompts, delay=delay)
        engine.output_dir = Path("exp") / exp / f"realtimeout_{lang}" 
        engine.output_dir.mkdir(parents=True, exist_ok=True)
        await engine.run_realtime(websocket)

    return app

def main():
    parser = argparse.ArgumentParser(description="Realtime Voice WS Server")
    parser.add_argument("--config", type=str, default="test_path_tts/config.yaml", help="YAMLé…ç½®æ–‡ä»¶è·¯å¾„")
    # parser.add_argument("--medium", type=str, default="realtime_out1",help="ä¸­é—´ç»“æœè¾“å‡ºç›®å½• (é»˜è®¤: realtime_out1)")
    # parser.add_argument("--host", default="0.0.0.0", help="Bind host")
    # parser.add_argument("--port", type=int, default=18000, help="Bind port")
    args = parser.parse_args()

    with open(args.config, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)

    server_cfg = cfg.get("server", {})
    prompts_cfg = cfg.get("prompts", {})

    host = server_cfg.get("host", {})
    port = server_cfg.get("port", {})
    delay = server_cfg.get("time", {})


    app = create_app(prompts_cfg, delay)
    uvicorn.run(app, host=host, port=port)

if __name__ == "__main__":
    main()